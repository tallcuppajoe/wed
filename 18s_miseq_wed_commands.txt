
#We need to create wed.stability.files which is simply a text file with the samples and the associated fastq files for the forward and reverse reads
#An example is in L:\lab\GenomicsNutrients\Computing\MiSeq_SOP. 
make.file(type=gz, input=D:\wed\data\18S\raw\wed.gz, outputdir=D:\wed\data\18S\raw)
#The result of the make.file command is a fileList.paired.file which we will rename
system(rename D:\wed\data\18S\raw\fileList.paired.file wed.stability.files)
#We will then use the stability files to make contigs and merge the forward and reverse reads
make.contigs(file=D:\wed\data\18S\raw\wed.stability.files, inputdir=D:\wed\data\18S\raw, outputdir=D:\wed\data\18S\process, processors=3)
#Look at the new contigs fasta using summary.seqs
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.fasta)
#Next we will screen.seqs to remove files that don't fit what we expect. The maxlength will change based on the results of the summary.seqs above
screen.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.fasta, group=wed.stability.contigs.groups, maxambig=0, maxlength=275)
#we can look at output to see if it looks better than before by looking at a summary
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.fasta)
#Next we remove tell mothur to only look at the unique sequences
unique.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.fasta)
#We will simplify the group names next and generate a count table
count.seqs(name=D:\wed\data\18S\process\wed.stability.trim.contigs.good.names, group=D:\wed\data\18S\process\wed.stability.contigs.good.groups)
#look at the count table with summary.seqs
summary.seqs(count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.count_table)
#We have already made the fasta for the v9 region of eukaryotes from silva and we can look at that file. This command might take a few minutes.
summary.seqs(fasta=D:\wed\data\18S\ref\silva.euk.v9.align)
#align the sample sequences to the reference file
align.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.fasta, reference=D:\wed\data\18S\ref\silva.euk.v9.align)
#as usual we should take a look at the sequences to see if we need to rerun screen.seqs (spoiler alert, we probably do)
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.align, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.count_table)
#Find the start and end values for the bulk of the sequences. rerun screen.seqs with these new values, as well as remove homopolymers above the number of the bulk of sequences
screen.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.align, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.count_table, summary=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.summary, start=1968, end=11550, maxhomop=8)
#next we'll want to look at the summary again, followed by removal of the overhangs at then ends. there won't be many since we did paired end sequencing.
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.align, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.good.count_table)
filter.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.align, vertical=T, trump=.)
#the last command told us our final alignment length. since we trimmed the ends we'll run unique.seqs again to remove any redundancies
unique.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.good.count_table)
#looking at a summary will tell us how many reduntant sequences we removed
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.count_table)
#denoise the sequences using pre.cluster and allow up to 2 differences between sequences
pre.cluster(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.count_table, diffs=2)
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.count_table)
#chimeras will exist in our sequence and we will remove them using uchime
chimera.uchime(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.count_table, dereplicate=t)
#while chimera.uchime removes the chimeras from the count file, we have to run a command to remove them from the fasta
remove.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.fasta, accnos=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.accnos)
#run a summary to see what we're left with
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.count_table)
#we want to remove chloroplasts, mitochondria, bacteria, and archaea.first we'll have to classify them, then we'll remove the unwanted lineages
classify.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.count_table, reference=D:\wed\data\18S\ref\silva.nr_v123.align, taxonomy=D:\wed\data\18S\ref\silva.nr_v123.tax, cutoff=80)
remove.lineage(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.count_table, taxonomy=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Bacteria)
#take a look to see how many unique sequences are left
summary.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table)
#the error rate can be assessed if a mock community was run. you should not use the mock to set up your quality parameters, but it is helpful to report.
get.groups(count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table, fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta, groups=Mock)
#the number of unique sequences will be displayed, as well as the total number of sequences. to assess the error rate we check the sequence error against the known sequences of the mock
seq.error(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, reference=D:\wed\data\18S\ref\d3_gb_mock.fasta, aligned=F)
#it is sometimes difficult to see the error rate on the screen. the error rate will be in the log file.
#cluster the mock sequences into OTU to see how many spurious OTU we have. the following commands work with the files generated above after get.groups so it only includes the mock community.
dist.seqs(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta, cutoff=0.20)
cluster(column=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.dist, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table)
make.shared(list=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.list, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, label=0.03)
rarefaction.single(shared=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.shared)
#the file generated is a .rarefaction file and provides the data for a rarefaction curve. this tells us how many OTU we have with sampling depth. do NOT expect the exact number in the mock community. it will be larger.
#moving forward, we want to remove the mock community from the analysis
remove.groups(count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table, fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta, taxonomy=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.taxonomy, groups=Mock)
#we will cluster the remaining samples. wed is a large dataset so splitting the clusters is more efficient.
cluster.split(fasta=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, taxonomy=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.taxonomy, splitmethod=classify, taxlevel=4, cutoff=0.15, processors=3)
#to find out how many sequences are in each OTU from each group we use make.shared, and we're interested up to a 0.03 cutoff, or 97% similiarity. the input is the file we just generated in the previous step.
make.shared(list=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.list, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, label=0.03)
#we get the consensus taxonomy for our OTU with the classify.out command
classify.otu(list=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.list, count=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, taxonomy=D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.taxonomy, label=0.03)
#open the .taxonomy file generated by the previous command to see the number of times an OTU was observed and the percent that were classified to that genus
#we want to perform some analysis, but those names are getting unweildy. we'll change them to tidy things up.
system(rename D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.shared wed.stability.an.shared)
system(rename D:\wed\data\18S\process\wed.stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.0.03.cons.taxonomy wed.stability.an.cons.taxonomy)
#The shared and taxonomy files an be taken into primer or R for analysis. the following commands are for further analysis within mothur
#next we'll want to see how many sequences are in each sample
count.groups(shared=D:\wed\data\18S\process\wed.stability.an.shared)
#we now see the number of sequences per sample. it is important to rarefy to the lowest number of sequences. this value will change depending on the output above. the number 2439 will change.
sub.sample(shared=D:\wed\data\18S\process\wed.stability.an.shared, size=2439)
#looking at alpha diversity first generate a rarefaction curve describing OTS as a function of sampling effort
rarefaction.single(shared=D:\wed\data\18S\process\wed.stability.an.shared, calc=sobs, freq=100)
#generate a table with sequence number, coverage, OTU number, and inverse simpson diversity. subsample=T tells the command to use the size of the smallest library. the output is a summary file.
summary.single(shared=D:\wed\data\18S\process\wed.stability.an.shared, calc=nseqs-coverage-sobs-invsimpson, subsample=T)
#Beta diversity is better assessed in Primer or R. The real goal of this analysis in mothur is to get good taxonomy and shared files for further analysis.

